{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50c43c6-f4a6-48e9-ac6c-1f92ec36d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaTokenizerFast, RobertaConfig, RobertaModelWithHeads\n",
    "from transformers import Trainer, TrainingArguments, EvalPrediction\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee68a40d-1905-4c7a-9685-897f8fe78f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gpu():\n",
    "    '''\n",
    "    check gpu status\n",
    "    '''\n",
    "    try:\n",
    "        print('GPU available:', torch.cuda.is_available())\n",
    "        print(torch.cuda.device_count(), 'GPUs detected')\n",
    "        print('Current GPU id:', torch.cuda.current_device())\n",
    "        print('Current GPU Name:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    except:\n",
    "        print('GPU not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43d83ef4-aa9d-41e3-89e8-6ed4378e3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(batch):\n",
    "    '''\n",
    "    Encodes a batch of input data using the model tokenizer\n",
    "    '''\n",
    "    return tokenizer(batch[\"text\"], max_length=80, truncation=True, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "615a97d6-2cd5-448c-aea3-64cc8bbfecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "1 GPUs detected\n",
      "Current GPU id: 0\n",
      "Current GPU Name: NVIDIA GeForce GTX 980 Ti\n"
     ]
    }
   ],
   "source": [
    "check_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb974c5-f4bb-43d6-b8ef-f6fae0d2ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for dataset, name: (classes, type of f1 score)\n",
    "dataset_dict = {'chemprot': (13, 'micro'), 'rct': (5, 'micro'),\n",
    "                'CI': (6, 'macro'), 'sciie': (7, 'm2cro'),\n",
    "                'HN': (2, 'macro'), 'ag': (4, 'macro'),\n",
    "                'amazon': (2, 'macro'), 'imdb': (2, 'macro')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "beb5379f-e5ae-425d-9242-8c102249e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'amazon'\n",
    "n_labels = dataset_dict[ds_name][0]\n",
    "f1_type = dataset_dict[ds_name][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ef76f85-4293-4193-b9ec-d14fed38c1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset task_dataset/task (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to C:\\Users\\snow-\\.cache\\huggingface\\datasets\\task_dataset\\task\\1.0.0\\d4dbb1ae1e5b21302597f18c62e58ab7f320999e2bdffea6d0514c3c329ad9ae...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset task_dataset downloaded and prepared to C:\\Users\\snow-\\.cache\\huggingface\\datasets\\task_dataset\\task\\1.0.0\\d4dbb1ae1e5b21302597f18c62e58ab7f320999e2bdffea6d0514c3c329ad9ae. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(f'data_loaders/{ds_name}_data_loader.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4d1187ef-72f5-4aff-b6b2-23df1cb57490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "# model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-base', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6b0d81d-67f9-45ba-810c-3429ceb6c776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700a9246b2d84a268a94b7e8842abf36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=226.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6995116ee914441a4e15ab1f7596106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a92a81f91864d8aa3dc99f8250be36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_encoded = dataset.map(encode_batch, batched=True, batch_size=512)\n",
    "# tokenized_datasets = dataset.map(tokenizer, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43774518-17bd-4579-804f-c13d6e2a4d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'text'],\n",
       "        num_rows: 115251\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'text'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'text'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "86436e9a-148d-4152-a5e6-5900741e935c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Works fine for my new Samsung Galaxy S3\\n\\nWorks great. No problems with my Samsung Galaxy S3.  It charges with no problems.  It lights up when it is charging.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_encoded['train']['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b20e87ac-b5eb-4da1-abdc-cca4a9fc72c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Works fine for my new Samsung Galaxy S3\\n\\nWorks great. No problems with my Samsung Galaxy S3.  It charges with no problems.  It lights up when it is charging.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset_encoded['train']['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a894f73-08a5-4a0d-b03e-e92371188ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bebd0204-9909-4435-96d8-96cba613a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"test-mlm\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "044fcfbd-ee57-4788-b746-7522c3e182c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_encoded[\"train\"],\n",
    "    eval_dataset=dataset_encoded[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6a1d501a-3daf-4f46-b52c-5b652ee5e893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='43221' max='43221' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43221/43221 2:46:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.656090</td>\n",
       "      <td>1.575830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.595609</td>\n",
       "      <td>1.496033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.521609</td>\n",
       "      <td>1.474264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=43221, training_loss=1.6328712460378056)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7506470b-a480-43ad-8d31-2ec17ceab896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 4.37\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8ec860db-a475-4d67-b705-9b35798f12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model in trainer format\n",
    "trainer.save_model('model/amazon_mlm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f945d082-b04f-4347-8c2e-1f6de8ac7a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save torch model\n",
    "torch.save(trainer.model, 'model/amazon_mlm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "befedc72-acf1-4e33-b3b0-a7c2aa81f073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(dataset_encoded['train'][0]['input_ids']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "65932c1e-d7f5-4f7b-8e71-90d7b1952e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[15.2053, -3.2850,  8.9295,  ...,  2.3371,  5.3764,  7.6053],\n",
       "         [ 5.9016, -2.7083,  9.5977,  ..., -1.4241,  1.3352,  2.5618],\n",
       "         [-0.7304, -4.5036,  3.2780,  ..., -0.7873, -1.0853, -0.2154],\n",
       "         ...,\n",
       "         [-0.1011, -5.6306,  5.3763,  ..., -5.6786, -3.1615,  1.2951],\n",
       "         [-0.1011, -5.6306,  5.3763,  ..., -5.6786, -3.1615,  1.2951],\n",
       "         [-0.1011, -5.6306,  5.3763,  ..., -5.6786, -3.1615,  1.2951]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model((torch.tensor(dataset_encoded['train'][0]['input_ids'])).unsqueeze(0).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3893955a-5397-4055-a0cb-d04bb3f94450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model status\n",
    "trainer.model.training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a459ec-74bd-456d-839d-2db2813b83c4",
   "metadata": {},
   "source": [
    "## Compare with raw RoBerta MLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8439468f-cfef-4dad-8441-b63d53fca59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_raw = RobertaForMaskedLM.from_pretrained('roberta-base', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "daf22bf6-98b0-4f9d-8c58-2e8626b67e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_raw = Trainer(\n",
    "    model=model_raw,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_encoded[\"train\"],\n",
    "    eval_dataset=dataset_encoded[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c59ca0a1-f56c-440e-8786-786f6a95eed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 13.99\n"
     ]
    }
   ],
   "source": [
    "eval_results_raw = trainer_raw.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results_raw['eval_loss']):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (DL_project)",
   "language": "python",
   "name": "pycharm-52f45b42"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
